# Required Libraries
library(glmnet) # For Elastic Net
library(Matrix) # For Sparse Matrix
library(caret) # For Preprocessing and K-Fold Validation
library(dplyr) # For Data Manipulation
library(data.table) # For Efficient Data Handling
library(doParallel) # For Parallel Computing

# Set Random Seed
set.seed(1)

# Load Dataset
zip_file <- "https://github.com/Uviase/Medici..Ne/blob/c50888d28ebf59b2c6ecf004182fc89993ba8a8f/dataset.zip"
temp_file <- tempfile()
download.file(zip_file, temp_file)
unzip(temp_file, exdir = tempdir())
dataset_path <- list.files(tempdir(), pattern = "\\.csv$", full.names = TRUE)
data <- fread(dataset_path)

# Data Preprocessing
# Extract useful columns
cognition_cols <- c("C", "F", "I", "L", "O", "R", "U", "X", "AA", "AD", "AG", "AJ", 
                    "AM", "AP", "AS", "AV", "AY", "BB", "BE", "BH", "BK", "BN", "BQ", 
                    "BT", "BW", "BZ", "CC", "CF", "CI", "CL")
temperature_cols <- c("A", "D", "G", "J", "M", "P", "S", "V", "Y", "AB", "AE", "AH", 
                      "AK", "AN", "AQ", "AT", "AW", "AZ", "BC", "BF", "BI", "BL", 
                      "BO", "BR", "BU", "BX", "CA", "CD", "CG", "CJ")
electrodermal_cols <- c("B", "E", "H", "K", "N", "Q", "T", "W", "Z", "AC", "AF", 
                        "AI", "AL", "AO", "AR", "AV", "AX", "BA", "BD", "BG", "BJ", 
                        "BM", "BP", "BS", "BV", "BY", "CB", "CE", "CH", "CK")

# Remove the second row of Electrodermal Activity columns
data <- data[-2, ]
data <- data[, lapply(.SD, as.numeric)]

# Log transform temperature columns
data[, (temperature_cols) := lapply(.SD, log), .SDcols = temperature_cols]

# Standardization (mean=0, sd=1)
pre_proc <- preProcess(data, method = c("center", "scale"))
data <- predict(pre_proc, data)

# Extract Dependent Variable (Cognition)
cognition <- as.numeric(data[1, ..cognition_cols]) # Cognition values for 30 rows (10 candidates × 3 exams)

# Create Predictors (30 × 6 features)
temp_features <- data[, ..temperature_cols]
eda_features <- data[, ..electrodermal_cols]
predictors <- cbind(temp_features, eda_features)

# Interaction Terms
interaction_terms <- model.matrix(~.^2 - 1, data = setDT(as.data.frame(predictors)))

# Zero/Low-Variance Filter
nzv_filter <- nearZeroVar(interaction_terms, saveMetrics = TRUE)
filtered_predictors <- interaction_terms[, !nzv_filter$nzv]

# Sparse Matrix Conversion
sparse_predictors <- as(filtered_predictors, "sparseMatrix")

# Dimensionality Reduction (Optional PCA if high-dimensional)
dim_reduction <- prcomp(sparse_predictors, scale. = TRUE)
reduced_predictors <- dim_reduction$x[, 1:30] # Retain top 30 components

# Elastic Net Model Training
alpha <- 0.5 # Elastic Net Mixing Parameter
lambda_seq <- 10^seq(3, -2, by = -0.1) # Lambda sequence for regularization
cv_results <- list()

# Parallel Computing Setup
cl <- makeCluster(detectCores() - 1)
registerDoParallel(cl)

# K-Fold Cross-Validation
k <- 10
folds <- createFolds(cognition, k = k, list = TRUE)
for (i in seq_along(folds)) {
  train_idx <- unlist(folds[-i])
  test_idx <- unlist(folds[i])
  
  # Train-Test Split
  train_x <- reduced_predictors[train_idx, ]
  train_y <- cognition[train_idx]
  test_x <- reduced_predictors[test_idx, ]
  test_y <- cognition[test_idx]
  
  # Elastic Net Training
  model <- cv.glmnet(train_x, train_y, alpha = alpha, lambda = lambda_seq, family = "gaussian", parallel = TRUE)
  
  # Evaluate Performance
  predictions <- predict(model, test_x, s = "lambda.min")
  rmse <- sqrt(mean((test_y - predictions)^2))
  cv_results[[i]] <- list(model = model, rmse = rmse)
}

# Stop Parallel Computing
stopCluster(cl)

# Aggregate Results
average_rmse <- mean(sapply(cv_results, function(res) res$rmse))
best_model <- cv_results[[which.min(sapply(cv_results, function(res) res$rmse))]]$model

# Feature Importance
feature_importance <- abs(coef(best_model, s = "lambda.min"))
feature_importance <- feature_importance[order(-feature_importance)]

# Output Results
cat("Average RMSE:", average_rmse, "\n")
cat("Top Features (Standardized Coefficients):\n")
print(feature_importance)
